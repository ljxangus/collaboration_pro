# Collaboration Protocol Revision

This update to the collaboration protocol is designed to support and accelerate runtime adaptation across different CIRNs. At the heart of this proposal is the recognition that there is one major category of information that is fundamental for collaboration that is missing in the existing collaboration protocol: CIRN A's impact on the operation of CIRN B. Philosophically, this can be viewed as critical for the wireless counterpart to the modification of the Golden Rule in the context of Diversity. "Do onto others as you would have them do unto you" works when we are all the same, but for a heterogeneous population, we need to follow "Do onto others as they would have you do unto them." This insight is reflected in the introduction of the Impact type of messages so we can understand how others perceive our actions.

The concept of Impact invites the key question of "impact on what?" What is the fundamental kind of impact that we believe is essential to all wireless networks, no matter how they are designed? For this, we propose that, with apologies to Jane Austen, that it should be a truth universally acknowledged that a network node in possession of a fortune of packets must be in want of a way to drain its queue and send those packets along to their destinations. Consequently, queue lengths (they could be virtual representing demand pressure here) and how resources can be used to drain queues are fundamental. CIRN A's impact on CIRN B is most directly on the ability of the nodes in CIRN B to drain their queues. Heterogeneous radio networks might have different conceptions of their resources and different ways of using those resources, but the internal goal of draining queues and sending data along is a universal. Fortunately, the line of work on wireless protocols that was initiated by Tassiulas and Ephremides' seminal 1992 paper (Stability Properties of Constrained Queuing and Scheduling Policies for Maximum Throughput in Multihop Radio Networks) in the Transactions on Automatic Control tells us that exchanging these queue lengths is actually sufficient for many decentralized wireless protocols to learn the optimal network configuration and operating point. While the work in the literature has been focused on a single completely co-designed network protocol, it is reasonable to presume that this information (universal as it is) is also going to play an important role in intelligent learned collaboration among networks that are not tightly co-designed. This insight is reflected in the introduction of a queue state information as a kind of Demand message as well as the introduction of queue draining information as a kind of Resource message. After all, a long queue is an indication of high demand. And the resources that a network has access to are fundamentally used to drain these queues. The speed of draining matters.

The final conceptual piece of this update to the collaboration protocol answers the question "How is it possible to estimate impact?" Since learning impact is vital for collaborating (otherwise, how would we know if we are stepping on their toes as we dance together?), it is natural to accelerate this. Since supervised learning is generally easier and faster than unsupervised learning, we propose adding a Content declaration. This allows a network to declare to other networks some details of selected transmissions so that others can presumably more easily learn the impact of such transmissions on them. Here, there is a further minor tweak of us adding a boolean "has ocurred" flag to a declaration so that the recipient can distinguish between something was intended as happening in the future from something that has already definitely happened in the past.

## Narrative use-case for new features to enable collaboration

Before some further comments on the details of our changes, it is useful to consider a potential narrative use-case where these additions to the collaboration protocol can show their value. Imagine that our network starts up. It senses incumbents and bootstraps a degree of connectivity within itself so that it can pass messages within itself without antagonizing incumbents. At this point, what it wants to do is learn how to share wireless resources better with the other networks in the area. To do so, it needs to understand the impact of its transmissions on others. So, what it does is share MakeDeclaration messages where it announces its intention to use specific different channels to transmit specific packets in the future from all of its nodes. By announcing it in advance, the other networks have a chance to quiet their own transmissions at around those times so that they can feel the full impact of these transmissions. After I transmit, I send out some additional MakeDeclarations that follow up with the precise time and content of the transmissions that were actually made.

Once they have listened at those times, they can compute for themselves the extent to which these transmissions would have interfered with the different channels that they use to receive messages. For each potential receiver and each potential transmitter and each potential channel, they can compute the extent to which this transmission would have interfered. This is because systems presumably have some kind of model of themselves and their own operation. They can view the energy they receive from our transmission as a kind of noise. At this point, the other systems know my impact on them. This impact can be expressed as a percentage --- how much does the presence of this transmission slow down the ability to use this resource to drain a queue? 0% means that it completely blocks. 100% means that it does not interfere at all. In between reflects a corresponding average degradation on the rate. Other networks can send me Impact declarations that convey this information. The important thing is that your network can talk about the impact in your own conception of how you potentially  use wireless resources in terms of SpectrumVoxels.

If you have sent me similar MakeDeclaration messages, then I would have listened, made such estimates, and sent them back to you. At this point, in the best case scenario, we have effectively learned the contention graph among resources used by us to drain our queues. The challenge remains how to find a strategy to actually transmit. For my own network, I can follow backpressure-style algorithms and basically make my packets flow maximally "downhill" (from long queues to shorter ones). However, how should we share? There is a clear choice here. I should use a fraction of resources corresponding to the relative lengths of the corresponding queues. A longer queue needs to be drained more often because it represents a congestion point. To support this style of resource sharing, we transmit MakeDeclaration messages sharing my queue lengths with the other CIRNs. The combination of the queue lengths with the Impact messages lets me schedule my resources for draining queues in a way that fairly contends with other networks because I know how my use of this will impact your ability to drain your queues.

As time goes on, I can keep this process going by sharing updated queue lengths as well as periodically scheduling known transmissions so that others can measure my impact on them. I can do this more or less frequently based on how fast I move. Others can do the same and can continue updating the impacts as they move. Thankfully, backpressure style approaches are generally quite robust to asynchrony.

## More details about protocol changes vis-a-vis alternatives

Throughout, things have been kept flexible. We don't assume that radio systems will use contiguous frequency channels to drain their queues, and so repeated SpectrumVoxels are used to represent a single "resource" that is being used. The basic idea of a queue is at the per-link level. Each link has a queue of packets that are waiting to be sent down that link. However, a radio node might have many choices of resources that could be used for that same link. This is why a single queue could be drained by any number of different resources that could be used to send packets along. We also don't assume that my network's conception of frequencies is the same as yours. This is why a single transmission can cast an impact shadow on multiple resources that could be used for transmission instead of being limited to the same frequencies.

Furthermore, rather than structuring the additions to the collaboration protocol in terms of interactive transactions, we have adopted a much more one-sided declaration approach. We feel that this is fundamentally more robust to potential degradations in the collaboration channel. In many cases, collaboration messages will be in some kind of conversation with each other. For example, my declaration of a future transmission is being done so that you can come back at some point with my impact on you. But this is not forced.

In some cases, we have backed away from a purely minimalist aesthetic. For example, the existing framework of sharing observations and requesting an observation of myself can in principle tell me how I sound to you. However, since our goal is to collaborate, it is much more useful to know what my impact is to you instead of trying to infer that purely from your behavior. In a related vein, the heart of resource-sharing collaboration happens at the time and locus of resource use. In wireless, this is at the transmitters. Consequently, we expect networks to digest the impact information in a way that sheds light on the transmitter side (which queues will have their drainage hampered) rather than at the receivers.

The other changes we have documented in a way that their motivation should be clear from the context and the comments that we added. Some are subtle. For example, it is important to view SpectrumVoxels in a per-queue way because multiple-antenna techniques will result in different impacts to transmissions using the same set of frequencies.


## Learning Philosophy motivations

This set of collaboration protocol proposals can be viewed as supporting the exchange of gradient-type information between networks. The literature on backpressure algorithms identifies the queue-lengths as a kind of shadow-price and Lagrange multiplier in a distributed optimization. The Impact information that we add here is also very clearly a kind of derivative --- how much does my performance locally degrade if you do X?

The rest of this can be viewed as adding a bit more of a supervised learning potential in terms of richer logs/plans that can be shared. This supervised learning dimension should help speed things up in impact estimation.

Although the queue length and impact information can help guide the selection of the right proportions of shared resource use in a decentralized way, it does not remove the need for local learning. The exact determination of how to share spectral resources is something that we believe really does require online learning. This is because different systems might have different styles of accessing the resource. For example, a CSMA style system can become more or less aggressive by adjusting its backoff timer. We expect this is something that will have to be learned online.

## Miscellaneous observation

The HTML documentation is very helpful as it extracts relevant comments and provides a document that is easier to read than the source code.  However, the documentation tool does not identify fields that are part of "oneof" blocks which enforce mutual exclusivity of fields.  For example, in Demand, the fields throughputs, latency, and priority are all part of a "oneof".  In the HTML documentation, they all appear as optional fields.  We would like to propose that either the documentation tool be re-evaluated or "oneof" blocks removed from the protocol. This is not in the patch per se, but is a comment to those merging patches.
